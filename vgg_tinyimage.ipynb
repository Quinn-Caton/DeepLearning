{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import six\n",
        "from keras.models import Model\n",
        "from keras.layers import ( Input, Activation, Dense, Flatten )\n",
        "import tensorflow as tf\n",
        "from keras.layers import ( Conv2D, MaxPooling2D, AveragePooling2D )\n",
        "from keras.layers import add\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import utils as np_utils\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import scipy.ndimage as nd\n",
        "\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input"
      ],
      "metadata": {
        "id": "QlvuV0Yfchhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_wG8lRSQ3tK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56464d35-0737-4363-96f0-49497cda9a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount( '/content/drive', force_remount=True )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/seshuad/IMagenet\n",
        "! ls 'IMagenet/tiny-imagenet-200/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-P1mgt6cANZ",
        "outputId": "bea656f7-b0ba-465a-f800-58e460754d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IMagenet'...\n",
            "remote: Enumerating objects: 120594, done.\u001b[K\n",
            "remote: Total 120594 (delta 0), reused 0 (delta 0), pack-reused 120594\u001b[K\n",
            "Receiving objects: 100% (120594/120594), 212.68 MiB | 15.02 MiB/s, done.\n",
            "Resolving deltas: 100% (1115/1115), done.\n",
            "Updating files: 100% (120206/120206), done.\n",
            "test  train  val  wnids.txt  words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import scipy.ndimage as nd\n",
        "import numpy as np\n",
        "\n",
        "path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "    return id_dict\n",
        "\n",
        "def get_class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])\n",
        "    return result\n",
        "\n",
        "def get_data(id_dict):\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [imageio.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), mode='RGB') for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open( path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data.append(imageio.imread( path + 'val/images/{}'.format(img_name) ,mode='RGB'))\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "    return np.array(train_data), np.array(train_labels), np.array(test_data), np.array(test_labels)\n",
        "\n",
        "train_data, train_labels, test_data, test_labels = get_data(get_id_dictionary())\n",
        "\n",
        "print( \"train data shape: \",  train_data.shape )\n",
        "print( \"train label shape: \", train_labels.shape )\n",
        "print( \"test data shape: \",   test_data.shape )\n",
        "print( \"test_labels.shape: \", test_labels.shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_LzIx7lcQsW",
        "outputId": "1bbd59a0-fbd9-4cfc-c388-c9de77565086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting loading data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-1a8933de63de>:30: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  train_data += [imageio.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), mode='RGB') for i in range(500)]\n",
            "<ipython-input-4-1a8933de63de>:37: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  test_data.append(imageio.imread( path + 'val/images/{}'.format(img_name) ,mode='RGB'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished loading data, in 47.86302638053894 seconds\n",
            "train data shape:  (100000, 64, 64, 3)\n",
            "train label shape:  (100000, 200)\n",
            "test data shape:  (10000, 64, 64, 3)\n",
            "test_labels.shape:  (10000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "inputs = keras.Input(shape=(64,64,3))"
      ],
      "metadata": {
        "id": "YvL4n3tCgmW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_data(train_data, train_labels ):\n",
        "    size = len(train_data)\n",
        "    train_idx = np.arange(size)\n",
        "    np.random.shuffle(train_idx)\n",
        "\n",
        "    return train_data[train_idx], train_labels[train_idx]\n",
        "\n",
        "train_data, train_labels = shuffle_data(train_data, train_labels)"
      ],
      "metadata": {
        "id": "aNcbDJl3dqHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "\n",
        "vgg19_model = VGG19(include_top = False, weights='imagenet', input_shape=(64, 64, 3))\n",
        "vgg19_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHjudqtMlhVs",
        "outputId": "df9b2281-e5ad-4b5d-b7b8-670f8e8c5943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 3s 0us/step\n",
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20024384 (76.39 MB)\n",
            "Trainable params: 20024384 (76.39 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, PReLU, GlobalAveragePooling2D\n",
        "\n",
        "vgg19_model.trainable = False\n",
        "x=vgg19_model.output\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "outputs = Dense(200, activation='softmax')(x)\n",
        "\n",
        "model=Model(inputs=vgg19_model.input, outputs=outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6udYDWOiej7A",
        "outputId": "3b7d71d2-9a1e-410b-c8b1-119fa8974ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 512)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 200)               205000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20754696 (79.17 MB)\n",
            "Trainable params: 730312 (2.79 MB)\n",
            "Non-trainable params: 20024384 (76.39 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
        "csv_logger = CSVLogger('resnet50_tiny_ImageNet.csv')\n",
        "\n",
        "batch_size = 500\n",
        "nb_classes = 200\n",
        "nb_epoch = 30\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 64, 64\n",
        "# The images are RGB\n",
        "img_channels = 3\n",
        "\n",
        "# The data, shuffled and split between train and test sets:\n",
        "X_train = train_data\n",
        "Y_train = train_labels\n",
        "X_test = test_data\n",
        "Y_test = test_labels\n",
        "\n",
        "X_train = preprocess_input(X_train)\n",
        "X_test = preprocess_input(X_test)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# subtract mean and normalize\n",
        "mean_image = np.mean(X_train, axis=0)\n",
        "X_train -= mean_image\n",
        "X_test -= mean_image\n",
        "X_train /= 128.\n",
        "X_test /= 128."
      ],
      "metadata": {
        "id": "F08uVhAfkAqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=.1)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])"
      ],
      "metadata": {
        "id": "mntrRG7Oltg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range = 10,\n",
        "        zoom_range = 0.1,\n",
        "        width_shift_range = 0.1,\n",
        "        height_shift_range = 0.1,\n",
        "        shear_range = 0.1,\n",
        "        horizontal_flip = True,\n",
        "        vertical_flip = False\n",
        "        )\n",
        "train_datagen.fit(X_train)\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "learning_rate_reduction = ReduceLROnPlateau(\n",
        "    monitor='val_categorical_accuracy',\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    factor=0.6,\n",
        "    min_lr=1e-6)"
      ],
      "metadata": {
        "id": "4Ahrndirl262"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vldwL24MuRv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_datagen.flow(X_train, Y_train, batch_size=500),\n",
        "          steps_per_epoch=len(X_train) // 500,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=30, verbose=1,\n",
        "          callbacks=[learning_rate_reduction, early_stopper])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwI8HV5yl4wP",
        "outputId": "eedccca0-cdc4-40ba-9e30-0a2e3af35116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "200/200 [==============================] - 110s 545ms/step - loss: 2.5972 - categorical_accuracy: 0.3769 - val_loss: 2.5169 - val_categorical_accuracy: 0.4008 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 109s 544ms/step - loss: 2.5738 - categorical_accuracy: 0.3821 - val_loss: 2.5060 - val_categorical_accuracy: 0.3981 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 109s 544ms/step - loss: 2.5628 - categorical_accuracy: 0.3833 - val_loss: 2.5094 - val_categorical_accuracy: 0.4016 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 110s 548ms/step - loss: 2.5444 - categorical_accuracy: 0.3870 - val_loss: 2.4987 - val_categorical_accuracy: 0.4015 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 109s 544ms/step - loss: 2.5334 - categorical_accuracy: 0.3896 - val_loss: 2.4983 - val_categorical_accuracy: 0.4035 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 109s 545ms/step - loss: 2.5156 - categorical_accuracy: 0.3914 - val_loss: 2.4948 - val_categorical_accuracy: 0.4029 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 109s 543ms/step - loss: 2.5137 - categorical_accuracy: 0.3926 - val_loss: 2.4981 - val_categorical_accuracy: 0.4061 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 108s 542ms/step - loss: 2.4942 - categorical_accuracy: 0.3980 - val_loss: 2.4947 - val_categorical_accuracy: 0.4037 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "200/200 [==============================] - 110s 548ms/step - loss: 2.4881 - categorical_accuracy: 0.3967 - val_loss: 2.5036 - val_categorical_accuracy: 0.4029 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.4803 - categorical_accuracy: 0.3999\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
            "200/200 [==============================] - 109s 546ms/step - loss: 2.4803 - categorical_accuracy: 0.3999 - val_loss: 2.4866 - val_categorical_accuracy: 0.4056 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "200/200 [==============================] - 109s 546ms/step - loss: 2.4368 - categorical_accuracy: 0.4083 - val_loss: 2.4811 - val_categorical_accuracy: 0.4048 - lr: 6.0000e-04\n",
            "Epoch 12/30\n",
            "200/200 [==============================] - 110s 548ms/step - loss: 2.4113 - categorical_accuracy: 0.4131 - val_loss: 2.4824 - val_categorical_accuracy: 0.4092 - lr: 6.0000e-04\n",
            "Epoch 13/30\n",
            "200/200 [==============================] - 109s 544ms/step - loss: 2.4076 - categorical_accuracy: 0.4135 - val_loss: 2.4782 - val_categorical_accuracy: 0.4091 - lr: 6.0000e-04\n",
            "Epoch 14/30\n",
            "200/200 [==============================] - 108s 541ms/step - loss: 2.3990 - categorical_accuracy: 0.4151 - val_loss: 2.4722 - val_categorical_accuracy: 0.4122 - lr: 6.0000e-04\n",
            "Epoch 15/30\n",
            "200/200 [==============================] - 109s 546ms/step - loss: 2.3913 - categorical_accuracy: 0.4152 - val_loss: 2.4749 - val_categorical_accuracy: 0.4114 - lr: 6.0000e-04\n",
            "Epoch 16/30\n",
            "200/200 [==============================] - 109s 543ms/step - loss: 2.3901 - categorical_accuracy: 0.4158 - val_loss: 2.4663 - val_categorical_accuracy: 0.4147 - lr: 6.0000e-04\n",
            "Epoch 17/30\n",
            "200/200 [==============================] - 109s 542ms/step - loss: 2.3764 - categorical_accuracy: 0.4196 - val_loss: 2.4639 - val_categorical_accuracy: 0.4137 - lr: 6.0000e-04\n",
            "Epoch 18/30\n",
            "200/200 [==============================] - 110s 547ms/step - loss: 2.3704 - categorical_accuracy: 0.4197 - val_loss: 2.4707 - val_categorical_accuracy: 0.4105 - lr: 6.0000e-04\n",
            "Epoch 19/30\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.3607 - categorical_accuracy: 0.4238\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
            "200/200 [==============================] - 109s 542ms/step - loss: 2.3607 - categorical_accuracy: 0.4238 - val_loss: 2.4846 - val_categorical_accuracy: 0.4055 - lr: 6.0000e-04\n",
            "Epoch 20/30\n",
            "200/200 [==============================] - 109s 544ms/step - loss: 2.3343 - categorical_accuracy: 0.4277 - val_loss: 2.4561 - val_categorical_accuracy: 0.4136 - lr: 3.6000e-04\n",
            "Epoch 21/30\n",
            "200/200 [==============================] - 109s 547ms/step - loss: 2.3331 - categorical_accuracy: 0.4278 - val_loss: 2.4545 - val_categorical_accuracy: 0.4119 - lr: 3.6000e-04\n",
            "Epoch 22/30\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.3281 - categorical_accuracy: 0.4263\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
            "200/200 [==============================] - 109s 547ms/step - loss: 2.3281 - categorical_accuracy: 0.4263 - val_loss: 2.4613 - val_categorical_accuracy: 0.4114 - lr: 3.6000e-04\n",
            "Epoch 23/30\n",
            "200/200 [==============================] - 110s 550ms/step - loss: 2.3012 - categorical_accuracy: 0.4354 - val_loss: 2.4535 - val_categorical_accuracy: 0.4114 - lr: 2.1600e-04\n",
            "Epoch 24/30\n",
            "200/200 [==============================] - 110s 547ms/step - loss: 2.3055 - categorical_accuracy: 0.4329 - val_loss: 2.4595 - val_categorical_accuracy: 0.4142 - lr: 2.1600e-04\n",
            "Epoch 25/30\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.2918 - categorical_accuracy: 0.4358\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
            "200/200 [==============================] - 110s 547ms/step - loss: 2.2918 - categorical_accuracy: 0.4358 - val_loss: 2.4570 - val_categorical_accuracy: 0.4137 - lr: 2.1600e-04\n",
            "Epoch 26/30\n",
            "200/200 [==============================] - 110s 551ms/step - loss: 2.2819 - categorical_accuracy: 0.4389 - val_loss: 2.4521 - val_categorical_accuracy: 0.4142 - lr: 1.2960e-04\n",
            "Epoch 27/30\n",
            "200/200 [==============================] - 109s 543ms/step - loss: 2.2829 - categorical_accuracy: 0.4378 - val_loss: 2.4544 - val_categorical_accuracy: 0.4125 - lr: 1.2960e-04\n",
            "Epoch 28/30\n",
            "200/200 [==============================] - 111s 552ms/step - loss: 2.2744 - categorical_accuracy: 0.4421 - val_loss: 2.4562 - val_categorical_accuracy: 0.4151 - lr: 1.2960e-04\n",
            "Epoch 29/30\n",
            "200/200 [==============================] - 109s 546ms/step - loss: 2.2797 - categorical_accuracy: 0.4394 - val_loss: 2.4518 - val_categorical_accuracy: 0.4147 - lr: 1.2960e-04\n",
            "Epoch 30/30\n",
            "200/200 [==============================] - 111s 552ms/step - loss: 2.2820 - categorical_accuracy: 0.4393 - val_loss: 2.4540 - val_categorical_accuracy: 0.4162 - lr: 1.2960e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ca9f53a6b60>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}